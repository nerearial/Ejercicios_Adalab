{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la pandas para poder trabajar en la lección\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe a partir de un diccionario de listas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>25</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juan</td>\n",
       "      <td>30</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>María</td>\n",
       "      <td>28</td>\n",
       "      <td>Valencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>35</td>\n",
       "      <td>Sevilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nombre  Edad     Ciudad\n",
       "0    Ana    25     Madrid\n",
       "1   Juan    30  Barcelona\n",
       "2  María    28   Valencia\n",
       "3  Pedro    35    Sevilla"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definimos un diccionario que luego convertiremos a DataFrame. Recordemos que esta era la forma que utilizamos en las lecciones del módulo 2 de web scraping\n",
    "data_diccionario = {\n",
    "    'Nombre': ['Ana', 'Juan', 'María', 'Pedro'],\n",
    "    'Edad': [25, 30, 28, 35],\n",
    "    'Ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla']\n",
    "}\n",
    "\n",
    "# convertimos el diccionario en DataFrame usando el método 'pd.DataFrame'\n",
    "df_diccionario = pd.DataFrame(data_diccionario)\n",
    "\n",
    "# mostramos el DataFrame. Recordad que para ver las 5 primeras filas usaremos el método '.head()' \n",
    "df_diccionario.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe a partir de una lista de diccionarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>25</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juan</td>\n",
       "      <td>30</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>María</td>\n",
       "      <td>28</td>\n",
       "      <td>Valencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>35</td>\n",
       "      <td>Sevilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nombre  Edad     Ciudad\n",
       "0    Ana    25     Madrid\n",
       "1   Juan    30  Barcelona\n",
       "2  María    28   Valencia\n",
       "3  Pedro    35    Sevilla"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definimos una lista de diccionarios que luego usaremos para convertir en DataFrame\n",
    "data_lista = [\n",
    "    {'Nombre': 'Ana', 'Edad': 25, 'Ciudad': 'Madrid'},\n",
    "    {'Nombre': 'Juan', 'Edad': 30, 'Ciudad': 'Barcelona'},\n",
    "    {'Nombre': 'María', 'Edad': 28, 'Ciudad': 'Valencia'},\n",
    "    {'Nombre': 'Pedro', 'Edad': 35, 'Ciudad': 'Sevilla'}\n",
    "]\n",
    "\n",
    "# usamos el método 'pd.DataFrame' para convertir la lista de diccionarios a DataFrame\n",
    "df_lista = pd.DataFrame(data_lista)\n",
    "\n",
    "# mostramos el DataFrame, en este caso usaremos el método '.tail()' para mostrar las últimas 5 filas. \n",
    "df_lista.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apertura de ficheros en Pandas\n",
    "\n",
    "En Pandas hay varios métodos disponibles para abrir distintos tipos de archivos. Algunos de los métodos más comunes para leer diferentes tipos de archivos en Pandas son los siguientes::\n",
    "\n",
    "1. `pd.read_csv`.\n",
    "\n",
    "2. `pd.read_excel`\n",
    "\n",
    "3. `pd.read_json`\n",
    "\n",
    "4. `pd.read_pickle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_csv()`\n",
    "\n",
    "La sintaxis básica de `pd.read_csv` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_csv(ruta_al_fichero , sep=',', delimiter=None, header='infer', names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `ruta_al_fichero`: Es la ruta del archivo CSV que deseas leer.\n",
    "\n",
    "- `sep` (opcional): Es el separador utilizado en el archivo CSV para separar los valores. Por defecto, es una coma (',').\n",
    "\n",
    "- `delimiter` (opcional): Es un alias para `sep`. Puedes usar `delimiter` en lugar de `sep` si prefieres.\n",
    "\n",
    "- `header` (opcional): Indica la fila del archivo CSV que se utilizará como encabezado de columnas. Puede tener los siguientes valores:\n",
    "  - `None`: No hay encabezado y los datos se leerán sin nombres de columna.\n",
    "  - `'infer'`: Intentará inferir automáticamente los nombres de columna del archivo.\n",
    "  - Un número *integer* que especifica la fila del archivo que se utilizará como encabezado de columna (por ejemplo, `header=0`).\n",
    "\n",
    "\n",
    "- `names` (opcional): Es una lista opcional de nombres para las columnas. Si se proporciona, reemplazará los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizará como índice del DataFrame resultante. Puede ser un número *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "Estos son solo algunos de los parámetros más comunes utilizados en `pd.read_csv`. La función `pd.read_csv` también admite muchos otros parámetros, como `skiprows`, `na_values`, `parse_dates` y más. Siempre podemos consultar la documentación oficial de este método [aquí](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) para obtener información más detallada sobre estos parámetros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>company_link</th>\n",
       "      <th>experience</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Frontend Developer</td>\n",
       "      <td>mexico</td>\n",
       "      <td>Hacienda San Pablo, México, Mexico</td>\n",
       "      <td>Vox Feed</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>Passion for building interfaces that bring the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>web developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               title country                            location  \\\n",
       "0   1  Frontend Developer  mexico  Hacienda San Pablo, México, Mexico   \n",
       "\n",
       "    company        date                                        description  \\\n",
       "0  Vox Feed  2019-08-18  Passion for building interfaces that bring the...   \n",
       "\n",
       "  company_link  experience       keywords  \n",
       "0          NaN           2  web developer  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs = pd.read_csv(\"jobs.csv\")\n",
    "df_jobs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la propia definición indica, nuestras columnas deben ir separadas por comas. A veces, puede ocurrir que no vengan separados por comas. Como en el ejemplo que vemos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24\n",
       "0  28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aire = pd.read_csv(\"aire.csv\")\n",
    "df_aire.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh oh... Algo ha salido mal... Si nos fijamos nuestras columnas están separadas por `;`. ¿Cómo podemos solucionar esto? \n",
    "\n",
    "> Usando el parámetro `sep` de `pd.read_csv` donde tendremos que especificar por qué están separadas mis columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>...</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "\n",
       "   h01 v01  ...  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  3.0   T  ...  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aire = pd.read_csv(\"aire.csv\", sep = \";\")\n",
    "df_aire.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_excel()`\n",
    "\n",
    "La sintaxis básica de `pd.read_excel` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_excel(ruta_al_fichero, sheet_name=0, header=0, names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `ruta_al_fichero`:  Es el nombre del archivo o la ruta de Excel que deseas leer. \n",
    "\n",
    "- `sheet_name` (opcional): Indica la hoja o hojas del archivo Excel que deseas leer. Puede tener los siguientes valores:\n",
    "\n",
    "  - Un número *integer* que especifica el índice de la hoja (por ejemplo, `sheet_name=0` para la primera hoja).\n",
    "\n",
    "  - Un nombre de hoja como una cadena (por ejemplo, `sheet_name='Sheet1'`).\n",
    "\n",
    "  - Una lista de nombres de hojas para leer varias hojas (por ejemplo, `sheet_name=['Sheet1', 'Sheet2']`).\n",
    "\n",
    "- `header` (opcional): Indica la fila del archivo Excel que se utilizará como encabezado de columnas. Puede tener los siguientes valores:\n",
    "\n",
    "  - `None`: No hay encabezado y los datos se leerán sin nombres de columna.\n",
    "\n",
    "  - Un número *integer* que especifica la fila del archivo que se utilizará como encabezado de columna (por ejemplo, `header=0`).\n",
    "\n",
    "- `names` (opcional): Es una lista opcional de nombres para las columnas. Si se proporciona, reemplazará los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizará como índice del DataFrame resultante. Puede ser un número *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "Además de estos parámetros, `pd.read_excel` también admite otros parámetros opcionales, como `skiprows`, `na_values`, `usecols` y más. Estos parámetros nos permiten personalizar aún más la lectura de archivos Excel según tus necesidades. Al igual que en el método `pd.read_csv()`, podemos  consultar la [documentación oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) para obtener información más detallada sobre estos parámetros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los ríos Manzanares, Lozoya y...</td>\n",
       "      <td>105655.000</td>\n",
       "      <td>1992-11-09</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los rí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rincón</td>\n",
       "      <td>15231.000</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rincón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Humedal de Importancia Internacional (RAMSAR)</td>\n",
       "      <td>Humedales del Macizo de Peñalara</td>\n",
       "      <td>487.198</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Humedales Ramsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protección para las Aves</td>\n",
       "      <td>Monte de El Pardo</td>\n",
       "      <td>15298.670</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protección para las Aves</td>\n",
       "      <td>Soto de Viñuelas</td>\n",
       "      <td>3071.890</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria  \\\n",
       "0  Áreas protegidas por instrumentos internacionales   \n",
       "1  Áreas protegidas por instrumentos internacionales   \n",
       "2  Áreas protegidas por instrumentos internacionales   \n",
       "3                Espacios Protegidos Red Natura 2000   \n",
       "4                Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                             espacio_prot_figura  \\\n",
       "0                         Reserva de la Biosfera   \n",
       "1                         Reserva de la Biosfera   \n",
       "2  Humedal de Importancia Internacional (RAMSAR)   \n",
       "3      Zona de Especial Protección para las Aves   \n",
       "4      Zona de Especial Protección para las Aves   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los ríos Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rincón   \n",
       "2                  Humedales del Macizo de Peñalara    \n",
       "3                                  Monte de El Pardo   \n",
       "4                                   Soto de Viñuelas   \n",
       "\n",
       "   espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655.000                     1992-11-09   \n",
       "1                   15231.000                     2005-06-29   \n",
       "2                     487.198                     2005-12-16   \n",
       "3                   15298.670                     1988-02-01   \n",
       "4                    3071.890                     1988-02-01   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa Áreas protegidas por instrumentos in...   \n",
       "1  Normativa Áreas protegidas por instrumentos in...   \n",
       "2  Normativa Áreas protegidas por instrumentos in...   \n",
       "3      Normativa Espacios Protegidos Red Natura 2000   \n",
       "4      Normativa Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                        espacio_prot_informacion_web  \n",
       "0  Reserva de la Biosfera Cuencas Altas de los rí...  \n",
       "1           Reserva de la Biosfera Sierra del Rincón  \n",
       "2                                   Humedales Ramsar  \n",
       "3                Espacios protegidos Red Natura 2000  \n",
       "4                Espacios protegidos Red Natura 2000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"espacios_protegidos.xlsx\", sheet_name=0)\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚨⚠️ **NOTA** Puede que al ejecutar este línea de código os salga el siguiente error: \n",
    "\n",
    "![error](https://github.com/Adalab/data_imagenes/blob/main/Pandas/error_excel.png?raw=true)\n",
    "\n",
    "**DON'T PANIC!!!** Lo único que tendreís que hacer es importaros `openpyxl`. ¿Cómo? \n",
    "\n",
    "- Nos vamos a la terminal y ejecutamos el siguiente código: \n",
    "\n",
    "```\n",
    "pip3 install openpyxl\n",
    "```\n",
    "\n",
    "o \n",
    "\n",
    "```\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_json()`\n",
    "\n",
    "La sintaxis básica de `pd.read_json` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_json(ruta_al_fichero, orient=None, typ='frame', dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False, precise_float=False, date_unit=None, encoding=None, lines=False)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `ruta_al_fichero`: Es la ruta del archivo JSON que deseas leer.\n",
    "\n",
    "- `orient` (opcional): Especifica la orientación del archivo JSON. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'columns'` (por defecto): Se espera que el archivo JSON tenga un formato de columna.\n",
    "\n",
    "  - `'index'`: Se espera que el archivo JSON tenga un formato de índice.\n",
    "\n",
    "  - `'records'`: Se espera que el archivo JSON tenga un formato de registros.\n",
    "\n",
    "  - `'split'`: Se espera que el archivo JSON tenga un formato dividido.\n",
    "\n",
    "  - `'values'`: Se espera que el archivo JSON contenga solo valores sin ninguna etiqueta de columna o índice.\n",
    "\n",
    "- `typ` (opcional): Indica el tipo de objeto a crear. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'frame'` (por defecto): Crea un objeto DataFrame.\n",
    "\n",
    "  - `'series'`: Crea un objeto Series.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "- `convert_axes` (opcional): Indica si las etiquetas de los ejes deben convertirse en índices o nombres de columna. Por defecto, es `True`.\n",
    "\n",
    "- `convert_dates` (opcional): Indica si se deben convertir las cadenas de fecha y hora en objetos de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `keep_default_dates` (opcional): Especifica si se deben mantener las fechas predeterminadas al convertir cadenas de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `numpy` (opcional): Indica si los datos deben devolverse como una matriz NumPy en lugar de un objeto DataFrame. Por defecto, es `False`.\n",
    "\n",
    "- `precise_float` (opcional): Indica si se deben utilizar números de punto *float* precisos en lugar de valores de punto *float* nativos de Python. Por defecto, es `False`.\n",
    "\n",
    "- `date_unit` (opcional): Especifica la unidad de fecha y hora si se deben convertir las cadenas de fecha y hora. Puede ser `'s'` para segundos o `'ms'` para milisegundos.\n",
    "\n",
    "- `encoding` (opcional): Permite especificar la codificación del archivo JSON si no se puede inferir automáticamente.\n",
    "\n",
    "- `lines` (opcional): Indica si el archivo JSON contiene múltiples objetos JSON en líneas separadas en lugar de un solo objeto JSON.\n",
    "\n",
    "Estos son solo algunos de los parámetros más comunes utilizados en `pd.read_json`. La función `pd.read_json` también admite otros parámetros opcionales, como `orient`, `date_format`, `numpy`, `compression` y más. Podemos consultar la [documentación oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html) para obtener información más detallada sobre estos parámetros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 23476.42, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 1927.25, 'resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 25333.54, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 22060.07, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 13109.74, 'res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'residuos_pelig_cantidad_ton': 23476.42, 'res...\n",
       "1  {'residuos_pelig_cantidad_ton': 1927.25, 'resi...\n",
       "2  {'residuos_pelig_cantidad_ton': 25333.54, 'res...\n",
       "3  {'residuos_pelig_cantidad_ton': 22060.07, 'res...\n",
       "4  {'residuos_pelig_cantidad_ton': 13109.74, 'res..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_residuos = pd.read_json(\"residuos.json\")\n",
    "df_residuos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residuos_pelig_cantidad_ton</th>\n",
       "      <th>residuos_pelig_año</th>\n",
       "      <th>residuos_pelig_opcion_gestion</th>\n",
       "      <th>residuos_pelig_tratamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23476.42</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperación de disolventes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperación de metales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25333.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Regeneración de aceite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22060.07</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorización</td>\n",
       "      <td>Trituración previa a valorización de baterías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109.74</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorización</td>\n",
       "      <td>Operaciones previas a valorización de RAEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   residuos_pelig_cantidad_ton  residuos_pelig_año  \\\n",
       "0                     23476.42                2012   \n",
       "1                      1927.25                2012   \n",
       "2                     25333.54                2012   \n",
       "3                     22060.07                2012   \n",
       "4                     13109.74                2012   \n",
       "\n",
       "                       residuos_pelig_opcion_gestion  \\\n",
       "0                                          Reciclado   \n",
       "1                                          Reciclado   \n",
       "2                                          Reciclado   \n",
       "3  Tratamiento previo a otras formas de valorización   \n",
       "4  Tratamiento previo a otras formas de valorización   \n",
       "\n",
       "                      residuos_pelig_tratamiento  \n",
       "0                    Recuperación de disolventes  \n",
       "1                        Recuperación de metales  \n",
       "2                         Regeneración de aceite  \n",
       "3  Trituración previa a valorización de baterías  \n",
       "4     Operaciones previas a valorización de RAEE  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esto nos devuelve un DataFrame que esta lleno de diccionarios!\n",
    "# sin embargo, lo podemos convertir fácilmente a algo más legible usando la siguiente sintaxis\n",
    "# este código no es necesario que lo entendamos ahora, más adelante según avancen las lecciones lo iremos entendiendo mejor!\n",
    "\n",
    "df_residuos2 = df_residuos['data'].apply(pd.Series)\n",
    "df_residuos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_pickle`\n",
    "\n",
    "\n",
    "**¿Qué es Pickle exactamente?**\n",
    "\n",
    "Un archivo de tipo pickle es un archivo binario en Python que se utiliza para serializar y deserializar objetos,  su acrónimo viene de *Python Pickle Format* que fue desarrollado exclusivamente para Python. Leyendo solo esto podemos seguir sin tener claro que es un archivo de tipo pickle. Expliquemoslo de una forma más sencilla. Imagina que tienes un montón de objetos especiales en tu habitación, como juguetes, libros, peluches, etc. Ahora, supongamos que quieres guardar todos estos objetos en una caja para poder llevarlos contigo o almacenarlos de manera segura.\n",
    "\n",
    "Aquí es donde entra en juego un archivo pickle. Es como una caja especial que te permite guardar todos estos objetos en ella. Pero, en lugar de objetos físicos, el archivo pickle puede almacenar objetos digitales, como datos, números, listas, diccionarios y más.\n",
    "\n",
    "El archivo pickle es como una caja mágica que puede guardar todos tus objetos digitales de Python. Cuando guardas estos objetos en un archivo pickle, se convierten en una forma especial que se puede almacenar en tu computadora o enviar a alguien más.\n",
    "\n",
    "La sintaxis básica de `pd.read_pickle` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_pickle(ruta_al_fichero, compression='infer')\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `filepath_or_buffer`: Es la ruta del archivo pickle que deseas leer.\n",
    "\n",
    "- `compression` (opcional): Es un parámetro opcional que indica el tipo de compresión utilizado en el archivo pickle. Por defecto, es `'infer'`, lo que significa que la biblioteca intentará inferir automáticamente el tipo de compresión. Puedes especificar un tipo de compresión explícitamente, como `'gzip'` o `'bz2'`, si el archivo pickle está comprimido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Colombia': 'Bogotá', 'Ecuador': 'Quito', 'Argentina': 'Buenos'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pkl = pd.read_pickle(\"paises_capitales.pkl\")\n",
    "df_pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.663px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
